{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0587f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DEEP NEURAL NETWORKS - ASSIGNMENT 2: CNN FOR IMAGE CLASSIFICATION\n",
    "Convolutional Neural Networks: Custom Implementation vs Transfer Learning\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ba03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_submission_readiness():\n",
    "    \"\"\"\n",
    "    Check if the notebook is ready for submission\n",
    "    Verifies all requirements are met\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üîç SUBMISSION READINESS CHECK\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Check student info\n",
    "    try:\n",
    "        if \"TODO\" in dataset_name or dataset_name == \"\":\n",
    "            issues.append(\"‚ùå Dataset name not filled\")\n",
    "        else:\n",
    "            print(\"‚úÖ Dataset name filled\")\n",
    "    except:\n",
    "        issues.append(\"‚ùå Dataset name variable not defined\")\n",
    "    \n",
    "    # Check if models are trained\n",
    "    try:\n",
    "        if custom_cnn_accuracy == 0.0:\n",
    "            issues.append(\"‚ùå Custom CNN not trained (accuracy is 0.0)\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Custom CNN trained (accuracy: {custom_cnn_accuracy:.4f})\")\n",
    "    except:\n",
    "        issues.append(\"‚ùå Custom CNN metrics not calculated\")\n",
    "    \n",
    "    try:\n",
    "        if tl_accuracy == 0.0:\n",
    "            issues.append(\"‚ùå Transfer Learning not trained (accuracy is 0.0)\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Transfer Learning trained (accuracy: {tl_accuracy:.4f})\")\n",
    "    except:\n",
    "        issues.append(\"‚ùå Transfer Learning metrics not calculated\")\n",
    "    \n",
    "    # Check GAP usage\n",
    "    try:\n",
    "        custom_summary = [layer.__class__.__name__ for layer in custom_cnn.layers]\n",
    "        if 'GlobalAveragePooling2D' in custom_summary:\n",
    "            print(\"‚úÖ Custom CNN uses Global Average Pooling\")\n",
    "        else:\n",
    "            issues.append(\"‚ùå Custom CNN missing Global Average Pooling\")\n",
    "    except:\n",
    "        issues.append(\"‚ùå Cannot verify Custom CNN architecture\")\n",
    "    \n",
    "    try:\n",
    "        tl_summary = [layer.__class__.__name__ for layer in transfer_model.layers]\n",
    "        if 'GlobalAveragePooling2D' in str(tl_summary):\n",
    "            print(\"‚úÖ Transfer Learning uses Global Average Pooling\")\n",
    "        else:\n",
    "            issues.append(\"‚ùå Transfer Learning missing Global Average Pooling\")\n",
    "    except:\n",
    "        issues.append(\"‚ùå Cannot verify Transfer Learning architecture\")\n",
    "    \n",
    "    # Check data split\n",
    "    if train_test_ratio == \"TODO: 90/10 OR 85/15\":\n",
    "        issues.append(\"‚ùå Train/test ratio not documented\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Train/test split documented: {train_test_ratio}\")\n",
    "    \n",
    "    # Final verdict\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    if issues:\n",
    "        print(\"‚ö†Ô∏è ISSUES FOUND - FIX BEFORE SUBMISSION:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  {issue}\")\n",
    "    else:\n",
    "        print(\"üéâ ALL CHECKS PASSED!\")\n",
    "        print(\"‚úÖ Notebook appears ready for submission\")\n",
    "    \n",
    "    if warnings:\n",
    "        print(\"\\n‚ö° WARNINGS:\")\n",
    "        for warning in warnings:\n",
    "            print(f\"  {warning}\")\n",
    "    \n",
    "    print(\"\\nüìù Final Steps:\")\n",
    "    print(\"  1. Run 'Restart & Run All' from Kernel menu\")\n",
    "    print(\"  2. Verify all outputs are visible\")\n",
    "    print(\"  3. Save notebook\")\n",
    "    print(\"  4. Rename file to: <BITS_ID>_cnn_assignment.ipynb\")\n",
    "    print(\"  5. Submit ONLY the .ipynb file\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# This will be called at the end of the notebook\n",
    "# Uncomment before submission to run the check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca408d",
   "metadata": {},
   "source": [
    "## üìã PRE-SUBMISSION CHECKLIST\n",
    "\n",
    "Run this cell before submission to ensure everything is ready:\n",
    "\n",
    "```python\n",
    "# Uncomment and run before submission\n",
    "# check_submission_readiness()\n",
    "```\n",
    "\n",
    "This will verify:\n",
    "- ‚úÖ All required metadata is filled\n",
    "- ‚úÖ Both models have been trained\n",
    "- ‚úÖ All metrics are calculated\n",
    "- ‚úÖ All outputs are visible\n",
    "- ‚úÖ Global Average Pooling is used\n",
    "- ‚úÖ File naming is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
    "\n",
    "BITS ID: [Enter your BITS ID here - e.g., 2025AA05036]\n",
    "Name: [Enter your full name here - e.g., JOHN DOE]\n",
    "Email: [Enter your email]\n",
    "Date: [Submission date]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ASSIGNMENT OVERVIEW\n",
    "\n",
    "This assignment requires you to implement and compare two CNN approaches for \n",
    "image classification:\n",
    "1. Custom CNN architecture using Keras/PyTorch\n",
    "2. Transfer Learning using pre-trained models (ResNet/VGG)\n",
    "\n",
    "Learning Objectives:\n",
    "- Design CNN architectures with Global Average Pooling\n",
    "- Apply transfer learning with pre-trained models\n",
    "- Compare custom vs pre-trained model performance\n",
    "- Use industry-standard deep learning frameworks\n",
    "\n",
    "IMPORTANT: Global Average Pooling (GAP) is MANDATORY for both models.\n",
    "DO NOT use Flatten + Dense layers in the final architecture.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3296a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " IMPORTANT SUBMISSION REQUIREMENTS - STRICTLY ENFORCED \n",
    "\n",
    "1. FILENAME FORMAT: <BITS_ID>_cnn_assignment.ipynb\n",
    "   Example: 2025AA05036_cnn_assignment.ipynb\n",
    "    Wrong filename = Automatic 0 marks\n",
    "\n",
    "2. STUDENT INFORMATION MUST MATCH:\n",
    "    BITS ID in filename = BITS ID in notebook (above)\n",
    "    Name in folder = Name in notebook (above)\n",
    "    Mismatch = 0 marks\n",
    "\n",
    "3. EXECUTE ALL CELLS BEFORE SUBMISSION:\n",
    "   - Run: Kernel ‚Üí Restart & Run All\n",
    "   - Verify all outputs are visible\n",
    "    No outputs = 0 marks\n",
    "\n",
    "4. FILE INTEGRITY:\n",
    "   - Ensure notebook opens without errors\n",
    "   - Check for corrupted cells\n",
    "    Corrupted file = 0 marks\n",
    "\n",
    "5. GLOBAL AVERAGE POOLING (GAP) MANDATORY:\n",
    "   - Both custom CNN and transfer learning must use GAP\n",
    "   - DO NOT use Flatten + Dense layers\n",
    "    Using Flatten+Dense = 0 marks for that model\n",
    "\n",
    "6. DATASET REQUIREMENTS:\n",
    "   - Minimum 500 images per class\n",
    "   - Train/test split: 90/10 OR 85/15\n",
    "   - 2-20 classes\n",
    "\n",
    "7. USE KERAS OR PYTORCH:\n",
    "   - Use standard model.fit() or training loops\n",
    "   - Do NOT implement convolution from scratch\n",
    "\n",
    "8. FILE SUBMISSION:\n",
    "   - Submit ONLY the .ipynb file\n",
    "   - NO zip files, NO separate data files, NO separate image files\n",
    "   - All code and outputs must be in the notebook\n",
    "   - Only one submission attempt allowed\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac286e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning frameworks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# For image processingprint(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional libraries for Kaggle dataset loading\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe565cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress tracking utilities\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "class ProgressTracker:\n",
    "    \"\"\"Track and display training progress\"\"\"\n",
    "    \n",
    "    def __init__(self, total_models=2):\n",
    "        self.total_models = total_models\n",
    "        self.completed_models = 0\n",
    "        self.current_model = None\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def start_model(self, model_name):\n",
    "        \"\"\"Start tracking a new model\"\"\"\n",
    "        self.current_model = model_name\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üöÄ Starting: {model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "    \n",
    "    def complete_model(self, model_name, training_time):\n",
    "        \"\"\"Mark a model as complete\"\"\"\n",
    "        self.completed_models += 1\n",
    "        print(f\"\\n‚úÖ Completed: {model_name} in {training_time:.2f}s\")\n",
    "        print(f\"üìä Progress: {self.completed_models}/{self.total_models} models completed\")\n",
    "    \n",
    "    def show_overall_progress(self):\n",
    "        \"\"\"Show overall progress\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"\\n‚è±Ô∏è Total elapsed time: {elapsed:.2f}s\")\n",
    "        print(f\"üìà Overall progress: {(self.completed_models/self.total_models)*100:.1f}%\")\n",
    "\n",
    "progress_tracker = ProgressTracker()\n",
    "print(\"‚úÖ Progress tracker initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"‚úÖ Random seeds set to {seed}\")\n",
    "\n",
    "set_seeds(config.random_seed)\n",
    "\n",
    "# Setup GPU if available\n",
    "def setup_gpu():\n",
    "    \"\"\"Configure GPU settings for optimal performance\"\"\"\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    \n",
    "    if gpus:\n",
    "        try:\n",
    "            # Enable memory growth to prevent TF from allocating all GPU memory\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "            # Enable mixed precision for faster training\n",
    "            if config.use_mixed_precision:\n",
    "                from tensorflow.keras import mixed_precision\n",
    "                policy = mixed_precision.Policy('mixed_float16')\n",
    "                mixed_precision.set_global_policy(policy)\n",
    "                print(f\"‚úÖ Mixed precision enabled (GPU detected)\")\n",
    "            \n",
    "            print(f\"‚úÖ GPU configured: {len(gpus)} GPU(s) available\")\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                print(f\"   GPU {i}: {gpu.name}\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"‚ö†Ô∏è GPU configuration error: {e}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No GPU detected - using CPU\")\n",
    "        print(\"   ‚ö° Tip: Training will be slower. Consider using Google Colab for GPU access.\")\n",
    "\n",
    "setup_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class TrainingManager:\n",
    "    \"\"\"Manages checkpointing, logging, and resumable training\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, config):\n",
    "        self.model_name = model_name\n",
    "        self.config = config\n",
    "        self.checkpoint_path = Path(config.checkpoint_dir) / model_name\n",
    "        self.logs_path = Path(config.logs_dir) / model_name\n",
    "        \n",
    "        # Create directories\n",
    "        self.checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.logs_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Training state\n",
    "        self.training_state = {\n",
    "            'epoch': 0,\n",
    "            'history': {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []},\n",
    "            'best_val_loss': float('inf'),\n",
    "            'training_time': 0.0,\n",
    "            'completed': False\n",
    "        }\n",
    "        \n",
    "        # Load existing checkpoint if available\n",
    "        self.load_checkpoint()\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        \"\"\"Load the latest checkpoint if it exists\"\"\"\n",
    "        checkpoint_file = self.checkpoint_path / 'training_state.pkl'\n",
    "        \n",
    "        if checkpoint_file.exists():\n",
    "            try:\n",
    "                with open(checkpoint_file, 'rb') as f:\n",
    "                    self.training_state = pickle.load(f)\n",
    "                print(f\"‚úÖ Loaded checkpoint for {self.model_name}\")\n",
    "                print(f\"   Last completed epoch: {self.training_state['epoch']}\")\n",
    "                print(f\"   Best val_loss: {self.training_state['best_val_loss']:.4f}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not load checkpoint: {e}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è No checkpoint found for {self.model_name} - starting fresh\")\n",
    "            return False\n",
    "    \n",
    "    def save_checkpoint(self, model, epoch, history, metrics):\n",
    "        \"\"\"Save model checkpoint and training state\"\"\"\n",
    "        if not self.config.save_checkpoints:\n",
    "            return\n",
    "        \n",
    "        # Update training state\n",
    "        self.training_state['epoch'] = epoch\n",
    "        self.training_state['history'] = history\n",
    "        \n",
    "        # Save training state\n",
    "        with open(self.checkpoint_path / 'training_state.pkl', 'wb') as f:\n",
    "            pickle.dump(self.training_state, f)\n",
    "        \n",
    "        # Save model weights\n",
    "        model_file = self.checkpoint_path / f'{self.model_name}_epoch_{epoch}.h5'\n",
    "        model.save_weights(str(model_file))\n",
    "        \n",
    "        # Save best model\n",
    "        val_loss = metrics.get('val_loss', float('inf'))\n",
    "        if val_loss < self.training_state['best_val_loss']:\n",
    "            self.training_state['best_val_loss'] = val_loss\n",
    "            best_model_file = self.checkpoint_path / f'{self.model_name}_best.h5'\n",
    "            model.save_weights(str(best_model_file))\n",
    "            print(f\"üíæ Saved best model (val_loss: {val_loss:.4f})\")\n",
    "    \n",
    "    def should_resume(self):\n",
    "        \"\"\"Check if training should resume from checkpoint\"\"\"\n",
    "        return (self.training_state['epoch'] > 0 and \n",
    "                not self.training_state['completed'])\n",
    "    \n",
    "    def get_initial_epoch(self):\n",
    "        \"\"\"Get the epoch number to resume from\"\"\"\n",
    "        return self.training_state['epoch']\n",
    "    \n",
    "    def mark_completed(self):\n",
    "        \"\"\"Mark training as completed\"\"\"\n",
    "        self.training_state['completed'] = True\n",
    "        with open(self.checkpoint_path / 'training_state.pkl', 'wb') as f:\n",
    "            pickle.dump(self.training_state, f)\n",
    "    \n",
    "    def log_metrics(self, epoch, metrics, mode='train'):\n",
    "        \"\"\"Log metrics to file\"\"\"\n",
    "        if not self.config.log_metrics:\n",
    "            return\n",
    "        \n",
    "        log_file = self.logs_path / f'{mode}_metrics.csv'\n",
    "        \n",
    "        # Create header if file doesn't exist\n",
    "        if not log_file.exists():\n",
    "            with open(log_file, 'w') as f:\n",
    "                f.write('timestamp,epoch,' + ','.join(metrics.keys()) + '\\n')\n",
    "        \n",
    "        # Append metrics\n",
    "        with open(log_file, 'a') as f:\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            values = ','.join([str(v) for v in metrics.values()])\n",
    "            f.write(f'{timestamp},{epoch},{values}\\n')\n",
    "\n",
    "# Test the training manager\n",
    "print(\"\\nüì¶ Training Manager initialized\")\n",
    "print(f\"   Checkpoint directory: {config.checkpoint_dir}\")\n",
    "print(f\"   Logs directory: {config.logs_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f42b9",
   "metadata": {},
   "source": [
    "## üîß UTILITY FUNCTIONS\n",
    "Helper functions for checkpointing, logging, and progress tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration for the entire project\"\"\"\n",
    "    \n",
    "    # ============ PATHS ============\n",
    "    data_dir: str = './data'\n",
    "    checkpoint_dir: str = './checkpoints'\n",
    "    logs_dir: str = './logs'\n",
    "    results_dir: str = './results'\n",
    "    \n",
    "    # ============ DATASET ============\n",
    "    dataset_slug: str = 'maedemaftouni/large-covid19-ct-slice-dataset'\n",
    "    img_size: Tuple[int, int] = (224, 224)\n",
    "    train_test_split: float = 0.10  # 90/10 split\n",
    "    \n",
    "    # ============ TRAINING - CUSTOM CNN ============\n",
    "    custom_batch_size: int = 32\n",
    "    custom_epochs: int = 20\n",
    "    custom_learning_rate: float = 0.001\n",
    "    custom_optimizer: str = 'Adam'\n",
    "    \n",
    "    # ============ TRAINING - TRANSFER LEARNING ============\n",
    "    tl_batch_size: int = 32\n",
    "    tl_epochs: int = 15\n",
    "    tl_learning_rate: float = 0.0001\n",
    "    tl_optimizer: str = 'Adam'\n",
    "    pretrained_model: str = 'ResNet50'  # Options: 'ResNet50', 'VGG16', 'MobileNetV2'\n",
    "    \n",
    "    # ============ OPTIMIZATION ============\n",
    "    use_mixed_precision: bool = True  # For faster training on compatible GPUs\n",
    "    cache_dataset: bool = True  # Cache preprocessed data\n",
    "    prefetch_buffer: int = tf.data.AUTOTUNE\n",
    "    \n",
    "    # ============ CHECKPOINTING ============\n",
    "    save_checkpoints: bool = True\n",
    "    checkpoint_frequency: int = 5  # Save every N epochs\n",
    "    save_best_only: bool = True\n",
    "    \n",
    "    # ============ LOGGING ============\n",
    "    verbose_training: int = 1  # 0=silent, 1=progress bar, 2=one line per epoch\n",
    "    log_metrics: bool = True\n",
    "    \n",
    "    # ============ REPRODUCIBILITY ============\n",
    "    random_seed: int = 42\n",
    "    \n",
    "    # ============ DEBUG MODE ============\n",
    "    debug_mode: bool = False  # Set True for faster debugging\n",
    "    debug_samples: int = 500  # Use limited samples in debug mode\n",
    "    debug_epochs: int = 2\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Adjust settings based on debug mode\"\"\"\n",
    "        if self.debug_mode:\n",
    "            print(\"‚ö†Ô∏è DEBUG MODE ENABLED - Using reduced dataset and epochs\")\n",
    "            self.custom_epochs = self.debug_epochs\n",
    "            self.tl_epochs = self.debug_epochs\n",
    "            self.custom_batch_size = min(16, self.custom_batch_size)\n",
    "            self.tl_batch_size = min(16, self.tl_batch_size)\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"‚úÖ Configuration initialized\")\n",
    "print(f\"   Debug Mode: {config.debug_mode}\")\n",
    "print(f\"   Image Size: {config.img_size}\")\n",
    "print(f\"   Custom CNN - Batch: {config.custom_batch_size}, Epochs: {config.custom_epochs}\")\n",
    "print(f\"   Transfer Learning - Batch: {config.tl_batch_size}, Epochs: {config.tl_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f8b08",
   "metadata": {},
   "source": [
    "## üìã CENTRALIZED CONFIGURATION\n",
    "All hyperparameters, paths, and settings are defined here for easy modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26692edf",
   "metadata": {},
   "source": [
    "## üöÄ QUICK START GUIDE\n",
    "\n",
    "### First Time Setup:\n",
    "1. **Set Kaggle Credentials**: Place `kaggle.json` in `~/.kaggle/` directory\n",
    "2. **Adjust Configuration**: Modify the `Config` class if needed (debug mode, epochs, batch size, etc.)\n",
    "3. **Run All Cells**: Execute from top to bottom\n",
    "\n",
    "### Resuming After Interruption:\n",
    "1. **Don't Panic!** Your progress is saved\n",
    "2. **Just Run All**: The training will automatically resume from the last checkpoint\n",
    "3. **Check Logs**: Look for \"üîÑ Resuming training from epoch X\" message\n",
    "\n",
    "### Debug Mode (Fast Iteration):\n",
    "```python\n",
    "config.debug_mode = True  # Uses fewer samples and epochs\n",
    "```\n",
    "\n",
    "### Production Mode:\n",
    "```python\n",
    "config.debug_mode = False  # Full dataset and training\n",
    "```\n",
    "\n",
    "### Changing Models:\n",
    "```python\n",
    "config.pretrained_model = 'ResNet50'  # or 'VGG16', 'MobileNetV2'\n",
    "```\n",
    "\n",
    "### Key Directories Created:\n",
    "- `./data/` - Downloaded dataset\n",
    "- `./checkpoints/` - Model weights and training state\n",
    "- `./logs/` - Training metrics and TensorBoard logs\n",
    "- `./results/` - Final outputs\n",
    "\n",
    "### ‚ö†Ô∏è Important Notes:\n",
    "- **Do NOT** delete checkpoint files during training\n",
    "- **Training can be interrupted** safely with Ctrl+C\n",
    "- **Kernel can be restarted** - training will resume\n",
    "- **All outputs are preserved** for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4d0a8",
   "metadata": {},
   "source": [
    "\n",
    "================================================================================\n",
    "PART 1: DATASET LOADING AND EXPLORATION\n",
    "================================================================================\n",
    "\n",
    "Instructions:\n",
    "1. Choose ONE dataset from the allowed list\n",
    "2. Load and explore the data\n",
    "3. Fill in ALL required metadata fields below\n",
    "4. Provide justification for your primary metric choice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da35481",
   "metadata": {},
   "source": [
    "## 1.1 Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: Fill in these metadata fields\n",
    "dataset_name = \"Large COVID-19 CT Slice Dataset\"\n",
    "dataset_source = \"Kaggle - maedemaftouni/large-covid19-ct-slice-dataset\"\n",
    "n_samples = 0  # Will be updated after loading\n",
    "n_classes = 2  # COVID and Non-COVID\n",
    "samples_per_class = \"Will be calculated after loading\"\n",
    "image_shape = [224, 224, 3]  # [height, width, channels]\n",
    "problem_type = \"classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary metric selection\n",
    "primary_metric = \"recall\"\n",
    "metric_justification = \"\"\"\n",
    "Recall is chosen as the primary metric for COVID-19 detection because minimizing false negatives \n",
    "is critical - we want to ensure that COVID-positive cases are not missed, even at the cost of \n",
    "some false positives which can be verified with additional tests.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25079b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Total Samples: {n_samples}\")\n",
    "print(f\"Number of Classes: {n_classes}\")\n",
    "print(f\"Samples per Class: {samples_per_class}\")\n",
    "print(f\"Image Shape: {image_shape}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")\n",
    "print(f\"Metric Justification: {metric_justification}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbf6de",
   "metadata": {},
   "source": [
    "## 1.2 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b3523",
   "metadata": {},
   "source": [
    "### 1.2.1 Setup Kaggle API\n",
    "First, ensure you have your Kaggle API credentials set up. You need to:\n",
    "1. Go to Kaggle ‚Üí Account ‚Üí API ‚Üí Create New API Token\n",
    "2. This downloads kaggle.json\n",
    "3. Place it in: `~/.kaggle/kaggle.json` (Linux/Mac) or `C:\\Users\\<YourUsername>\\.kaggle\\kaggle.json` (Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Set paths using config\n",
    "data_dir = Path(config.data_dir)\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Kaggle API authenticated successfully!\")\n",
    "print(f\"   Data directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b6064",
   "metadata": {},
   "source": [
    "### 1.2.2 Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f204de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset (only if not already downloaded)\n",
    "dataset_slug = config.dataset_slug\n",
    "download_path = str(data_dir)\n",
    "\n",
    "# Check if dataset already exists\n",
    "dataset_exists = any(data_dir.iterdir()) if data_dir.exists() else False\n",
    "\n",
    "if not dataset_exists:\n",
    "    print(f\"üì• Downloading dataset: {dataset_slug}\")\n",
    "    print(f\"   Destination: {download_path}\")\n",
    "    \n",
    "    # Download dataset\n",
    "    api.dataset_download_files(dataset_slug, path=download_path, unzip=True)\n",
    "    print(\"‚úÖ Dataset downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Dataset already exists at {download_path}\")\n",
    "\n",
    "print(f\"\\nüìÅ Files in {download_path}:\")\n",
    "for item in os.listdir(download_path):\n",
    "    print(f\"   - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4dad7",
   "metadata": {},
   "source": [
    "### 1.2.3 Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore dataset structure\n",
    "def explore_dataset_structure(base_path):\n",
    "    \"\"\"Explore and print the dataset directory structure\"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    \n",
    "    print(\"Dataset Structure:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Find all subdirectories\n",
    "    subdirs = [d for d in base_path.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not subdirs:\n",
    "        print(f\"No subdirectories found in {base_path}\")\n",
    "        print(\"\\nListing all items:\")\n",
    "        for item in base_path.iterdir():\n",
    "            print(f\"  {item.name} - {'Dir' if item.is_dir() else 'File'}\")\n",
    "    else:\n",
    "        for subdir in subdirs:\n",
    "            # Count images in each subdirectory\n",
    "            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "            image_files = [f for f in subdir.iterdir() \n",
    "                          if f.is_file() and f.suffix.lower() in image_extensions]\n",
    "            \n",
    "            print(f\"\\n{subdir.name}/\")\n",
    "            print(f\"  Number of images: {len(image_files)}\")\n",
    "            \n",
    "            if image_files:\n",
    "                # Show first few filenames\n",
    "                print(f\"  Sample files:\")\n",
    "                for img in image_files[:3]:\n",
    "                    print(f\"    - {img.name}\")\n",
    "    \n",
    "    return subdirs\n",
    "\n",
    "subdirs = explore_dataset_structure(data_dir)\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776bb75",
   "metadata": {},
   "source": [
    "### 1.2.4 Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image paths and labels\n",
    "def load_image_paths_and_labels(base_path):\n",
    "    \"\"\"\n",
    "    Load all image paths and their corresponding labels\n",
    "    Returns: image_paths (list), labels (list), class_names (list)\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = []\n",
    "    \n",
    "    # Image extensions to look for\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    \n",
    "    # Get all subdirectories (each represents a class)\n",
    "    class_dirs = sorted([d for d in base_path.iterdir() if d.is_dir()])\n",
    "    \n",
    "    if not class_dirs:\n",
    "        print(\"Warning: No class directories found!\")\n",
    "        # Try to find images directly in the base path\n",
    "        all_images = [f for f in base_path.iterdir() \n",
    "                     if f.is_file() and f.suffix.lower() in image_extensions]\n",
    "        if all_images:\n",
    "            print(f\"Found {len(all_images)} images in base directory\")\n",
    "            # Try to infer classes from filenames\n",
    "            return all_images, [0] * len(all_images), ['unknown']\n",
    "    \n",
    "    class_names = [d.name for d in class_dirs]\n",
    "    print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "    \n",
    "    # Load images from each class directory\n",
    "    for class_idx, class_dir in enumerate(class_dirs):\n",
    "        class_images = [f for f in class_dir.iterdir() \n",
    "                       if f.is_file() and f.suffix.lower() in image_extensions]\n",
    "        \n",
    "        print(f\"  {class_names[class_idx]}: {len(class_images)} images\")\n",
    "        \n",
    "        for img_path in class_images:\n",
    "            image_paths.append(str(img_path))\n",
    "            labels.append(class_idx)\n",
    "    \n",
    "    print(f\"\\nTotal images loaded: {len(image_paths)}\")\n",
    "    \n",
    "    return image_paths, labels, class_names\n",
    "\n",
    "# Load the data\n",
    "image_paths, labels, class_names = load_image_paths_and_labels(data_dir)\n",
    "\n",
    "# Update metadata\n",
    "n_samples = len(image_paths)\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Calculate samples per class\n",
    "from collections import Counter\n",
    "label_counts = Counter(labels)\n",
    "samples_per_class = f\"min: {min(label_counts.values())}, max: {max(label_counts.values())}, avg: {n_samples // n_classes}\"\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    count = label_counts[idx]\n",
    "    percentage = (count / n_samples) * 100\n",
    "    print(f\"  {class_name}: {count} images ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea151b6",
   "metadata": {},
   "source": [
    "### 1.2.5 Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a76788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def visualize_samples(image_paths, labels, class_names, samples_per_class=5):\n",
    "    \"\"\"Display sample images from each class\"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_classes, samples_per_class, \n",
    "                            figsize=(samples_per_class * 3, n_classes * 3))\n",
    "    \n",
    "    if n_classes == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for class_idx in range(n_classes):\n",
    "        # Get images for this class\n",
    "        class_image_indices = [i for i, label in enumerate(labels) if label == class_idx]\n",
    "        \n",
    "        # Select random samples\n",
    "        sample_indices = np.random.choice(class_image_indices, \n",
    "                                        min(samples_per_class, len(class_image_indices)), \n",
    "                                        replace=False)\n",
    "        \n",
    "        for i, img_idx in enumerate(sample_indices):\n",
    "            img_path = image_paths[img_idx]\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                axes[class_idx, i].imshow(img)\n",
    "                axes[class_idx, i].axis('off')\n",
    "                if i == 0:\n",
    "                    axes[class_idx, i].set_title(f'{class_names[class_idx]}\\n({img.shape[0]}x{img.shape[1]})', \n",
    "                                                fontsize=10, fontweight='bold')\n",
    "                else:\n",
    "                    axes[class_idx, i].set_title(f'{img.shape[0]}x{img.shape[1]}', fontsize=8)\n",
    "    \n",
    "    plt.suptitle('Sample Images from Dataset', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display samples\n",
    "visualize_samples(image_paths, labels, class_names, samples_per_class=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc3dfe",
   "metadata": {},
   "source": [
    "## 1.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8056167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional Keras utilities for data processing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to numpy array\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Apply debug mode limits if enabled\n",
    "if config.debug_mode and len(image_paths) > config.debug_samples:\n",
    "    print(f\"‚ö†Ô∏è DEBUG MODE: Limiting dataset to {config.debug_samples} samples\")\n",
    "    # Stratified sampling to maintain class balance\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    image_paths, _, labels_array, _ = train_test_split(\n",
    "        image_paths, labels_array,\n",
    "        train_size=config.debug_samples,\n",
    "        stratify=labels_array,\n",
    "        random_state=config.random_seed\n",
    "    )\n",
    "    n_samples = len(image_paths)\n",
    "    print(f\"   Using {n_samples} samples for debugging\")\n",
    "\n",
    "# Split data into train and validation sets using config\n",
    "X_train_paths, X_val_paths, y_train, y_val = train_test_split(\n",
    "    image_paths, labels_array, \n",
    "    test_size=config.train_test_split, \n",
    "    stratify=labels_array, \n",
    "    random_seed=config.random_seed\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Split:\")\n",
    "print(f\"   Training samples: {len(X_train_paths)}\")\n",
    "print(f\"   Validation samples: {len(X_val_paths)}\")\n",
    "print(f\"   Split ratio: {(1-config.train_test_split)*100:.0f}/{config.train_test_split*100:.0f}\")\n",
    "\n",
    "print(f\"\\nüìà Class distribution in training set:\")\n",
    "train_counts = Counter(y_train)\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"   {class_name}: {train_counts[idx]} images ({train_counts[idx]/len(y_train)*100:.1f}%)\")\n",
    "    \n",
    "print(f\"\\nüìà Class distribution in validation set:\")\n",
    "val_counts = Counter(y_val)\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"   {class_name}: {val_counts[idx]} images ({val_counts[idx]/len(y_val)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: Document your split (updated from config)\n",
    "train_test_ratio = f\"{int((1-config.train_test_split)*100)}/{int(config.train_test_split*100)}\"\n",
    "train_samples = len(X_train_paths)\n",
    "test_samples = len(X_val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46820f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
    "print(f\"Training Samples: {train_samples}\")\n",
    "print(f\"Test Samples: {test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimized data generators with augmentation\n",
    "def create_data_generators(train_paths, train_labels, val_paths, val_labels, \n",
    "                          img_size=(224, 224), batch_size=32):\n",
    "    \"\"\"\n",
    "    Create training and validation data generators with optimizations\n",
    "    \"\"\"\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Only rescaling for validation (no augmentation)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create DataFrames for flow_from_dataframe\n",
    "    train_df = pd.DataFrame({\n",
    "        'filename': train_paths,\n",
    "        'class': train_labels.astype(str)\n",
    "    })\n",
    "    \n",
    "    val_df = pd.DataFrame({\n",
    "        'filename': val_paths,\n",
    "        'class': val_labels.astype(str)\n",
    "    })\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=config.random_seed\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Create generators using config settings\n",
    "print(\"\\nüîÑ Creating data generators...\")\n",
    "\n",
    "# Use different batch sizes for custom CNN and transfer learning if needed\n",
    "# For now, we'll use custom_batch_size as default\n",
    "train_generator, val_generator = create_data_generators(\n",
    "    X_train_paths, y_train, \n",
    "    X_val_paths, y_val,\n",
    "    img_size=config.img_size,\n",
    "    batch_size=config.custom_batch_size\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data generators created:\")\n",
    "print(f\"   Training batches: {len(train_generator)}\")\n",
    "print(f\"   Validation batches: {len(val_generator)}\")\n",
    "print(f\"   Image size: {config.img_size}\")\n",
    "print(f\"   Batch size: {config.custom_batch_size}\")\n",
    "print(f\"   Classes: {train_generator.class_indices}\")\n",
    "print(f\"\\n‚ö° Optimization features:\")\n",
    "print(f\"   Mixed precision: {config.use_mixed_precision}\")\n",
    "print(f\"   Prefetch buffer: {'AUTO' if config.prefetch_buffer == tf.data.AUTOTUNE else config.prefetch_buffer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af1702",
   "metadata": {},
   "source": [
    "\n",
    "================================================================================\n",
    "PART 2: CUSTOM CNN IMPLEMENTATION (5 MARKS)\n",
    "================================================================================\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Build CNN using Keras/PyTorch layers\n",
    "- Architecture must include:\n",
    "  * Conv2D layers (at least 2)\n",
    "  * Pooling layers (MaxPool or AvgPool)\n",
    "  * Global Average Pooling (GAP) - MANDATORY\n",
    "  * Output layer (Softmax for multi-class)\n",
    "- Use model.compile() and model.fit() (Keras) OR standard PyTorch training\n",
    "- Track initial_loss and final_loss\n",
    "\n",
    "PROHIBITED:\n",
    "- Using Flatten + Dense layers instead of GAP\n",
    "- Implementing convolution from scratch\n",
    "\n",
    "GRADING:\n",
    "- Architecture design with GAP: 2 marks\n",
    "- Model properly compiled/configured: 1 mark\n",
    "- Training completed with loss tracking: 1 mark\n",
    "- All metrics calculated correctly: 1 mark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecef713",
   "metadata": {},
   "source": [
    "## 2.1 Custom CNN Architecture Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9a9a5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_custom_cnn(input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build custom CNN architecture with Global Average Pooling\n",
    "    \n",
    "    Args:\n",
    "        input_shape: tuple (height, width, channels)\n",
    "        n_classes: number of output classes\n",
    "    \n",
    "    Returns:\n",
    "        model: compiled CNN model\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import (Conv2D, MaxPooling2D, \n",
    "                                         GlobalAveragePooling2D, Dense,\n",
    "                                         Dropout, BatchNormalization)\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Block 1\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Global Average Pooling (MANDATORY - replaces Flatten)\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layer\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ], name='Custom_CNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instance\n",
    "print(\"\\nüèóÔ∏è Building Custom CNN...\")\n",
    "custom_cnn = build_custom_cnn(tuple(config.img_size) + (3,), n_classes)\n",
    "\n",
    "# Display model summary\n",
    "custom_cnn.summary()\n",
    "\n",
    "print(f\"\\n‚úÖ Custom CNN created\")\n",
    "print(f\"   Total parameters: {custom_cnn.count_params():,}\")\n",
    "print(f\"   Uses Global Average Pooling: ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e18bca",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "custom_cnn.compile(\n",
    "    optimizer=Adam(learning_rate=config.custom_learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Custom CNN compiled\")\n",
    "print(f\"   Optimizer: {config.custom_optimizer}\")\n",
    "print(f\"   Learning rate: {config.custom_learning_rate}\")\n",
    "print(f\"   Loss function: categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2c20b",
   "metadata": {},
   "source": [
    "## 2.2 Train Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CUSTOM CNN TRAINING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Training Manager for checkpointing and resumable execution\n",
    "custom_cnn_manager = TrainingManager('custom_cnn', config)\n",
    "progress_tracker.start_model('Custom CNN')\n",
    "\n",
    "# Track training time\n",
    "custom_cnn_start_time = time.time()\n",
    "\n",
    "# Check if we should resume from checkpoint\n",
    "initial_epoch = 0\n",
    "if custom_cnn_manager.should_resume():\n",
    "    print(f\"\\nüîÑ Resuming training from epoch {custom_cnn_manager.get_initial_epoch()}\")\n",
    "    initial_epoch = custom_cnn_manager.get_initial_epoch()\n",
    "    \n",
    "    # Load model weights from checkpoint\n",
    "    checkpoint_file = custom_cnn_manager.checkpoint_path / 'custom_cnn_best.h5'\n",
    "    if checkpoint_file.exists():\n",
    "        custom_cnn.load_weights(str(checkpoint_file))\n",
    "        print(f\"   Loaded weights from {checkpoint_file.name}\")\n",
    "else:\n",
    "    print(f\"\\nüéØ Starting training from scratch\")\n",
    "\n",
    "print(f\"   Total epochs: {config.custom_epochs}\")\n",
    "print(f\"   Batch size: {config.custom_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with resumable execution\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üèãÔ∏è TRAINING CUSTOM CNN\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    # Train model\n",
    "    history = custom_cnn.fit(\n",
    "        train_generator,\n",
    "        epochs=config.custom_epochs,\n",
    "        initial_epoch=initial_epoch,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=config.verbose_training\n",
    "    )\n",
    "    \n",
    "    # Mark training as completed\n",
    "    custom_cnn_manager.mark_completed()\n",
    "    \n",
    "    # Calculate training time\n",
    "    custom_cnn_training_time = time.time() - custom_cnn_start_time\n",
    "    \n",
    "    # Track initial and final loss\n",
    "    custom_cnn_initial_loss = history.history['loss'][0]\n",
    "    custom_cnn_final_loss = history.history['loss'][-1]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"   Training time: {custom_cnn_training_time:.2f}s ({custom_cnn_training_time/60:.2f} min)\")\n",
    "    print(f\"   Initial loss: {custom_cnn_initial_loss:.4f}\")\n",
    "    print(f\"   Final loss: {custom_cnn_final_loss:.4f}\")\n",
    "    print(f\"   Loss improvement: {((custom_cnn_initial_loss - custom_cnn_final_loss) / custom_cnn_initial_loss * 100):.2f}%\")\n",
    "    \n",
    "    # Update progress tracker\n",
    "    progress_tracker.complete_model('Custom CNN', custom_cnn_training_time)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    print(\"   Progress has been saved. You can resume training by running this cell again.\")\n",
    "    custom_cnn_training_time = time.time() - custom_cnn_start_time\n",
    "    custom_cnn_initial_loss = None\n",
    "    custom_cnn_final_loss = None\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during training: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9793e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Custom CNN: Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_title('Custom CNN: Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Custom CNN: Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b43f6b",
   "metadata": {},
   "source": [
    "## 2.4 Visualize Custom CNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Custom CNN on validation set\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìä EVALUATING CUSTOM CNN\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = custom_cnn.predict(val_generator, verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Calculate metrics\n",
    "custom_cnn_accuracy = accuracy_score(y_true, y_pred)\n",
    "custom_cnn_precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "custom_cnn_recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "custom_cnn_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"‚úÖ Custom CNN Performance:\")\n",
    "print(f\"   Accuracy:  {custom_cnn_accuracy:.4f} ({custom_cnn_accuracy*100:.2f}%)\")\n",
    "print(f\"   Precision: {custom_cnn_precision:.4f}\")\n",
    "print(f\"   Recall:    {custom_cnn_recall:.4f}\")\n",
    "print(f\"   F1-Score:  {custom_cnn_f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82329f",
   "metadata": {},
   "source": [
    "## 2.3 Evaluate Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks for checkpointing and early stopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "# Checkpoint callback - saves best model\n",
    "if config.save_checkpoints:\n",
    "    checkpoint_cb = ModelCheckpoint(\n",
    "        filepath=str(custom_cnn_manager.checkpoint_path / 'custom_cnn_best.h5'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=config.save_best_only,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(checkpoint_cb)\n",
    "\n",
    "# Early stopping - prevents overfitting\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "callbacks.append(early_stop_cb)\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "callbacks.append(reduce_lr_cb)\n",
    "\n",
    "# TensorBoard for visualization (optional)\n",
    "if config.log_metrics:\n",
    "    tensorboard_cb = TensorBoard(\n",
    "        log_dir=str(custom_cnn_manager.logs_path),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "    callbacks.append(tensorboard_cb)\n",
    "\n",
    "print(f\"\\n‚úÖ Callbacks configured:\")\n",
    "print(f\"   - Model checkpointing: {config.save_checkpoints}\")\n",
    "print(f\"   - Early stopping (patience=5)\")\n",
    "print(f\"   - Learning rate reduction (patience=3)\")\n",
    "print(f\"   - TensorBoard logging: {config.log_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44e29f",
   "metadata": {},
   "source": [
    "\n",
    "================================================================================\n",
    "PART 3: TRANSFER LEARNING IMPLEMENTATION (5 MARKS)\n",
    "================================================================================\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use pre-trained model: ResNet18/ResNet50 OR VGG16/VGG19\n",
    "- Freeze base layers (feature extractor)\n",
    "- Replace final layers with:\n",
    "  * Global Average Pooling (GAP) - MANDATORY\n",
    "  * Custom classification head\n",
    "- Fine-tune on your dataset\n",
    "- Track initial_loss and final_loss\n",
    "\n",
    "GRADING:\n",
    "- Valid base model with frozen layers: 2 marks\n",
    "- GAP + custom head properly implemented: 1 mark\n",
    "- Training completed with loss tracking: 1 mark\n",
    "- All metrics calculated correctly: 1 mark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46faf47a",
   "metadata": {},
   "source": [
    "## 3.1 Load Pre-trained Model and Modify Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48caeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSFER LEARNING IMPLEMENTATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc9879",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model (using config)\n",
    "pretrained_model_name = config.pretrained_model\n",
    "print(f\"üì¶ Loading pre-trained model: {pretrained_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21aea31",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_transfer_learning_model(base_model_name, input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build transfer learning model with Global Average Pooling\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: string (ResNet50/VGG16/MobileNetV2)\n",
    "        input_shape: tuple (height, width, channels)\n",
    "        n_classes: number of output classes\n",
    "    \n",
    "    Returns:\n",
    "        model: compiled transfer learning model with GAP\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.applications import ResNet50, VGG16, MobileNetV2\n",
    "    \n",
    "    # Load pre-trained model without top layers\n",
    "    if base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build custom head with Global Average Pooling\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # MANDATORY - replaces Flatten\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=base_model.input, outputs=outputs, name=f'TL_{base_model_name}')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create transfer learning model\n",
    "print(f\"\\nüèóÔ∏è Building Transfer Learning Model with {pretrained_model_name}...\")\n",
    "transfer_model, base_model = build_transfer_learning_model(\n",
    "    pretrained_model_name,\n",
    "    tuple(config.img_size) + (3,),\n",
    "    n_classes\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "transfer_model.summary()\n",
    "\n",
    "# Count frozen and trainable layers\n",
    "frozen_layers = sum([not layer.trainable for layer in transfer_model.layers])\n",
    "trainable_layers = sum([layer.trainable for layer in transfer_model.layers])\n",
    "total_parameters = transfer_model.count_params()\n",
    "trainable_parameters = sum([np.prod(v.get_shape()) for v in transfer_model.trainable_weights])\n",
    "\n",
    "print(f\"\\n‚úÖ Transfer Learning Model created:\")\n",
    "print(f\"   Base Model: {pretrained_model_name}\")\n",
    "print(f\"   Frozen Layers: {frozen_layers}\")\n",
    "print(f\"   Trainable Layers: {trainable_layers}\")\n",
    "print(f\"   Total Parameters: {total_parameters:,}\")\n",
    "print(f\"   Trainable Parameters: {trainable_parameters:,}\")\n",
    "print(f\"   Uses Global Average Pooling: ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94b6a7",
   "metadata": {},
   "source": [
    "### Compile Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the transfer learning model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=config.tl_learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Transfer Learning Model compiled\")\n",
    "print(f\"   Optimizer: {config.tl_optimizer}\")\n",
    "print(f\"   Learning rate: {config.tl_learning_rate}\")\n",
    "print(f\"   Loss function: categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490b4fd",
   "metadata": {},
   "source": [
    "## 3.2 Train Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d460091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Training Manager for Transfer Learning\n",
    "tl_manager = TrainingManager('transfer_learning', config)\n",
    "progress_tracker.start_model('Transfer Learning')\n",
    "\n",
    "# Recreate generators with TL batch size\n",
    "if config.tl_batch_size != config.custom_batch_size:\n",
    "    print(f\"\\nüîÑ Creating new generators with batch size {config.tl_batch_size}...\")\n",
    "    tl_train_generator, tl_val_generator = create_data_generators(\n",
    "        X_train_paths, y_train,\n",
    "        X_val_paths, y_val,\n",
    "        img_size=config.img_size,\n",
    "        batch_size=config.tl_batch_size\n",
    "    )\n",
    "else:\n",
    "    print(f\"\\n‚ôªÔ∏è Reusing existing generators\")\n",
    "    tl_train_generator = train_generator\n",
    "    tl_val_generator = val_generator\n",
    "\n",
    "# Track training time\n",
    "tl_start_time = time.time()\n",
    "\n",
    "# Training configuration from config\n",
    "tl_learning_rate = config.tl_learning_rate\n",
    "tl_epochs = config.tl_epochs\n",
    "tl_batch_size = config.tl_batch_size\n",
    "tl_optimizer = config.tl_optimizer\n",
    "\n",
    "# Check if we should resume from checkpoint\n",
    "initial_epoch = 0\n",
    "if tl_manager.should_resume():\n",
    "    print(f\"\\nüîÑ Resuming training from epoch {tl_manager.get_initial_epoch()}\")\n",
    "    initial_epoch = tl_manager.get_initial_epoch()\n",
    "    \n",
    "    # Load model weights from checkpoint\n",
    "    checkpoint_file = tl_manager.checkpoint_path / 'transfer_learning_best.h5'\n",
    "    if checkpoint_file.exists():\n",
    "        transfer_model.load_weights(str(checkpoint_file))\n",
    "        print(f\"   Loaded weights from {checkpoint_file.name}\")\n",
    "else:\n",
    "    print(f\"\\nüéØ Starting training from scratch\")\n",
    "\n",
    "print(f\"   Total epochs: {tl_epochs}\")\n",
    "print(f\"   Batch size: {tl_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks for Transfer Learning\n",
    "tl_callbacks = []\n",
    "\n",
    "# Checkpoint callback\n",
    "if config.save_checkpoints:\n",
    "    tl_checkpoint_cb = ModelCheckpoint(\n",
    "        filepath=str(tl_manager.checkpoint_path / 'transfer_learning_best.h5'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=config.save_best_only,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    tl_callbacks.append(tl_checkpoint_cb)\n",
    "\n",
    "# Early stopping\n",
    "tl_early_stop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "tl_callbacks.append(tl_early_stop_cb)\n",
    "\n",
    "# Reduce learning rate\n",
    "tl_reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-8,\n",
    "    verbose=1\n",
    ")\n",
    "tl_callbacks.append(tl_reduce_lr_cb)\n",
    "\n",
    "# TensorBoard\n",
    "if config.log_metrics:\n",
    "    tl_tensorboard_cb = TensorBoard(\n",
    "        log_dir=str(tl_manager.logs_path),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "    tl_callbacks.append(tl_tensorboard_cb)\n",
    "\n",
    "print(f\"\\n‚úÖ Callbacks configured for Transfer Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c156f",
   "metadata": {},
   "source": [
    "# Train Transfer Learning Model with resumable execution\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üèãÔ∏è TRAINING TRANSFER LEARNING MODEL\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    # Train model\n",
    "    tl_history = transfer_model.fit(\n",
    "        tl_train_generator,\n",
    "        epochs=tl_epochs,\n",
    "        initial_epoch=initial_epoch,\n",
    "        validation_data=tl_val_generator,\n",
    "        callbacks=tl_callbacks,\n",
    "        verbose=config.verbose_training\n",
    "    )\n",
    "    \n",
    "    # Mark training as completed\n",
    "    tl_manager.mark_completed()\n",
    "    \n",
    "    # Calculate training time\n",
    "    tl_training_time = time.time() - tl_start_time\n",
    "    \n",
    "    # Track initial and final loss\n",
    "    tl_initial_loss = tl_history.history['loss'][0]\n",
    "    tl_final_loss = tl_history.history['loss'][-1]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"   Training time: {tl_training_time:.2f}s ({tl_training_time/60:.2f} min)\")\n",
    "    print(f\"   Initial loss: {tl_initial_loss:.4f}\")\n",
    "    print(f\"   Final loss: {tl_final_loss:.4f}\")\n",
    "    print(f\"   Loss improvement: {((tl_initial_loss - tl_final_loss) / tl_initial_loss * 100):.2f}%\")\n",
    "    \n",
    "    # Update progress tracker\n",
    "    progress_tracker.complete_model('Transfer Learning', tl_training_time)\n",
    "    progress_tracker.show_overall_progress()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    print(\"   Progress has been saved. You can resume training by running this cell again.\")\n",
    "    tl_training_time = time.time() - tl_start_time\n",
    "    tl_initial_loss = None\n",
    "    tl_final_loss = None\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during training: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bdec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for Transfer Learning\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "axes[0].plot(tl_history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(tl_history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title(f'{pretrained_model_name}: Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "axes[1].plot(tl_history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(tl_history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_title(f'{pretrained_model_name}: Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "tl_cm = confusion_matrix(tl_y_true, tl_y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(tl_cm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'{pretrained_model_name}: Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e66e2",
   "metadata": {},
   "source": [
    "## 3.4 Visualize Transfer Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Transfer Learning Model\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìä EVALUATING TRANSFER LEARNING MODEL\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Get predictions\n",
    "tl_y_pred_proba = transfer_model.predict(tl_val_generator, verbose=0)\n",
    "tl_y_pred = np.argmax(tl_y_pred_proba, axis=1)\n",
    "tl_y_true = tl_val_generator.classes\n",
    "\n",
    "# Calculate metrics\n",
    "tl_accuracy = accuracy_score(tl_y_true, tl_y_pred)\n",
    "tl_precision = precision_score(tl_y_true, tl_y_pred, average='weighted', zero_division=0)\n",
    "tl_recall = recall_score(tl_y_true, tl_y_pred, average='weighted', zero_division=0)\n",
    "tl_f1 = f1_score(tl_y_true, tl_y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"‚úÖ Transfer Learning Performance:\")\n",
    "print(f\"   Accuracy:  {tl_accuracy:.4f} ({tl_accuracy*100:.2f}%)\")\n",
    "print(f\"   Precision: {tl_precision:.4f}\")\n",
    "print(f\"   Recall:    {tl_recall:.4f}\")\n",
    "print(f\"   F1-Score:  {tl_f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(tl_y_true, tl_y_pred, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4de0c4",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate Transfer Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee53330",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "================================================================================## 4.1 Metrics Comparison\n",
    "\n",
    "PART 4: MODEL COMPARISON AND VISUALIZATION\n",
    "\n",
    "================================================================================- Convergence behavior\n",
    "\n",
    "- Model complexity\n",
    "\n",
    "Compare both models on:- Training time\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f57abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)', 'Parameters'],\n",
    "    'Custom CNN': [\n",
    "        custom_cnn_accuracy,\n",
    "        custom_cnn_precision,\n",
    "        custom_cnn_recall,\n",
    "        custom_cnn_f1,\n",
    "        custom_cnn_training_time,\n",
    "        0  # TODO: Fill with custom CNN total parameters\n",
    "    ],\n",
    "    'Transfer Learning': [\n",
    "        tl_accuracy,\n",
    "        tl_precision,\n",
    "        tl_recall,\n",
    "        tl_f1,\n",
    "        tl_training_time,\n",
    "        trainable_parameters\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecacaf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e7240",
   "metadata": {},
   "source": [
    "## 4.2 Visual Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde9ab6",
   "metadata": {},
   "source": [
    "\n",
    "================================================================================\n",
    "PART 5: ANALYSIS (2 MARKS)\n",
    "================================================================================\n",
    "\n",
    "REQUIRED:\n",
    "- Write MAXIMUM 200 words (guideline - no marks deduction if exceeded)\n",
    "- Address key topics with depth\n",
    "\n",
    "GRADING (Quality-based):\n",
    "- Covers 5+ key topics with deep understanding: 2 marks\n",
    "- Covers 3-4 key topics with good understanding: 1 mark\n",
    "- Covers <3 key topics or superficial: 0 marks\n",
    "\n",
    "Key Topics:\n",
    "1. Performance comparison with specific metrics\n",
    "2. Pre-training vs training from scratch impact\n",
    "3. GAP effect on performance/overfitting\n",
    "4. Computational cost comparison\n",
    "5. Transfer learning insights\n",
    "6. Convergence behavior differences\n",
    "\n",
    "## 5.1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_text = \"\"\"\n",
    "TODO: Write your analysis here (maximum 200 words guideline)\n",
    "\n",
    "Address:\n",
    "1. Which model performed better and by how much?\n",
    "   [Compare specific metrics]\n",
    "\n",
    "2. Impact of pre-training vs training from scratch?\n",
    "   [Discuss feature extraction, convergence speed]\n",
    "\n",
    "3. Effect of Global Average Pooling?\n",
    "   [Discuss parameter reduction, overfitting prevention]\n",
    "\n",
    "4. Computational cost comparison?\n",
    "   [Compare training time, total parameters]\n",
    "\n",
    "5. Insights about transfer learning?\n",
    "   [When to use transfer learning vs custom CNN]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED: Print analysis with word count\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(analysis_text)\n",
    "print(f\"\\nAnalysis word count: {len(analysis_text.split())} words\")\n",
    "if len(analysis_text.split()) > 200:\n",
    "    print(\"‚ö†Ô∏è Warning: Analysis exceeds 200 words (guideline)\")\n",
    "else:\n",
    "    print(\"‚úÖ Analysis within word count guideline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462eda75",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "\n",
    "================================================================================\n",
    "PART 6: ASSIGNMENT RESULTS SUMMARY (REQUIRED FOR AUTO-GRADING)\n",
    "================================================================================\n",
    "\n",
    "DO NOT MODIFY THE STRUCTURE BELOW\n",
    "This JSON output is used by the auto-grader\n",
    "Ensure all field names are EXACT\n",
    "\n",
    "## 6.1 Generate Results JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39387e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_assignment_results():\n",
    "    \"\"\"\n",
    "    Generate complete assignment results in required format\n",
    "    \n",
    "    Returns:\n",
    "        dict: Complete results with all required fields\n",
    "    \"\"\"\n",
    "    \n",
    "    framework_used = \"keras\"  # TODO: Change to \"pytorch\" if using PyTorch\n",
    "    \n",
    "    results = {\n",
    "        # Dataset Information\n",
    "        'dataset_name': dataset_name,\n",
    "        'dataset_source': dataset_source,\n",
    "        'n_samples': n_samples,\n",
    "        'n_classes': n_classes,\n",
    "        'samples_per_class': samples_per_class,\n",
    "        'image_shape': image_shape,\n",
    "        'problem_type': problem_type,\n",
    "        'primary_metric': primary_metric,\n",
    "        'metric_justification': metric_justification,\n",
    "        'train_samples': train_samples,\n",
    "        'test_samples': test_samples,\n",
    "        'train_test_ratio': train_test_ratio,\n",
    "        \n",
    "        # Custom CNN Results\n",
    "        'custom_cnn': {\n",
    "            'framework': framework_used,\n",
    "            'architecture': {\n",
    "                'conv_layers': 0,  # TODO: Count your conv layers\n",
    "                'pooling_layers': 0,  # TODO: Count your pooling layers\n",
    "                'has_global_average_pooling': True,  # MUST be True\n",
    "                'output_layer': 'softmax',\n",
    "                'total_parameters': 0  # TODO: Calculate total parameters\n",
    "            },\n",
    "            'training_config': {\n",
    "                'learning_rate': 0.001,  # TODO: Your actual learning rate\n",
    "                'n_epochs': 20,  # TODO: Your actual epochs\n",
    "                'batch_size': 32,  # TODO: Your actual batch size\n",
    "                'optimizer': 'Adam',  # TODO: Your actual optimizer\n",
    "                'loss_function': 'categorical_crossentropy'  # TODO: Your actual loss\n",
    "            },\n",
    "            'initial_loss': custom_cnn_initial_loss,\n",
    "            'final_loss': custom_cnn_final_loss,\n",
    "            'training_time_seconds': custom_cnn_training_time,\n",
    "            'accuracy': custom_cnn_accuracy,\n",
    "            'precision': custom_cnn_precision,\n",
    "            'recall': custom_cnn_recall,\n",
    "            'f1_score': custom_cnn_f1\n",
    "        },\n",
    "        \n",
    "        # Transfer Learning Results\n",
    "        'transfer_learning': {\n",
    "            'framework': framework_used,\n",
    "            'base_model': pretrained_model_name,\n",
    "            'frozen_layers': frozen_layers,\n",
    "            'trainable_layers': trainable_layers,\n",
    "            'has_global_average_pooling': True,  # MUST be True\n",
    "            'total_parameters': total_parameters,\n",
    "            'trainable_parameters': trainable_parameters,\n",
    "            'training_config': {\n",
    "                'learning_rate': tl_learning_rate,\n",
    "                'n_epochs': tl_epochs,\n",
    "                'batch_size': tl_batch_size,\n",
    "                'optimizer': tl_optimizer,\n",
    "                'loss_function': 'categorical_crossentropy'\n",
    "            },\n",
    "            'initial_loss': tl_initial_loss,\n",
    "            'final_loss': tl_final_loss,\n",
    "            'training_time_seconds': tl_training_time,\n",
    "            'accuracy': tl_accuracy,\n",
    "            'precision': tl_precision,\n",
    "            'recall': tl_recall,\n",
    "            'f1_score': tl_f1\n",
    "        },\n",
    "        \n",
    "        # Analysis\n",
    "        'analysis': analysis_text,\n",
    "        'analysis_word_count': len(analysis_text.split()),\n",
    "        \n",
    "        # Training Success Indicators\n",
    "        'custom_cnn_loss_decreased': custom_cnn_final_loss < custom_cnn_initial_loss if custom_cnn_initial_loss and custom_cnn_final_loss else False,\n",
    "        'transfer_learning_loss_decreased': tl_final_loss < tl_initial_loss if tl_initial_loss and tl_final_loss else False,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print results\n",
    "try:\n",
    "    assignment_results = get_assignment_results()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
    "    print(json.dumps(assignment_results, indent=2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n  ERROR generating results: {str(e)}\")\n",
    "    print(\"Please ensure all variables are properly defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ENVIRONMENT VERIFICATION - SCREENSHOT REQUIRED\n",
    "\n",
    "IMPORTANT: Take a screenshot of your environment showing account details\n",
    "\n",
    "For Google Colab:\n",
    "- Click on your profile icon (top right)\n",
    "- Screenshot should show your email/account clearly\n",
    "- Include the entire Colab interface with notebook name visible\n",
    "\n",
    "For BITS Virtual Lab:\n",
    "- Screenshot showing your login credentials/account details\n",
    "- Include the entire interface with your username/session info visible\n",
    "\n",
    "Paste the screenshot below this cell or in a new markdown cell.\n",
    "This helps verify the work was done by you in your environment.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display system information\n",
    "import platform\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ENVIRONMENT INFORMATION\")\n",
    "print(\"\\n  REQUIRED: Add screenshot of your Google Colab/BITS Virtual Lab\")\n",
    "print(\"showing your account details in the cell below this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FINAL CHECKLIST - VERIFY BEFORE SUBMISSION\n",
    "\n",
    "‚ñ° Student information filled at the top (BITS ID, Name, Email)\n",
    "‚ñ° Filename is <BITS_ID>_cnn_assignment.ipynb\n",
    "‚ñ° All cells executed (Kernel ‚Üí Restart & Run All)\n",
    "‚ñ° All outputs visible\n",
    "‚ñ° Custom CNN implemented with Global Average Pooling (NO Flatten+Dense)\n",
    "‚ñ° Transfer learning implemented with GAP\n",
    "‚ñ° Both models use Keras or PyTorch (NOT from scratch)\n",
    "‚ñ° Both models trained with loss tracking (initial_loss and final_loss)\n",
    "‚ñ° All 4 metrics calculated for both models\n",
    "‚ñ° Primary metric selected and justified\n",
    "‚ñ° Analysis written (quality matters, not just word count)\n",
    "‚ñ° Visualizations created\n",
    "‚ñ° Assignment results JSON printed at the end\n",
    "‚ñ° No execution errors in any cell\n",
    "‚ñ° File opens without corruption\n",
    "‚ñ° Submit ONLY .ipynb file (NO zip, NO data files, NO images)\n",
    "‚ñ° Only one submission attempt\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
